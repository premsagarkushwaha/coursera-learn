{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_summarization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Text Summarization**\n",
        "Text summarization in NLP is the process of summarizing the information in large texts for quicker consumption.\n",
        "The technique, where a computer program shortens longer texts and generates summaries to pass the intended message, is defined as Automatic Text Summarization and is a common problem in machine learning and natural language processing (NLP).\n",
        "Text summarization is the process of creating a short, coherent, and fluent summary of a longer text document and involves the outlining of the textâ€™s major points.\n",
        "Text identification, interpretation and summary generation, and analysis of the generated summary are some of the key challenges faced in the process of text summarization. The critical tasks in extraction-based summarization are identifying key phrases in the document and using them to discover relevant information to be included in the summary. Two different approaches that are used for text summarization are:\n",
        "Extractive Summarization\n",
        "Abstractive Summarization\n"
      ],
      "metadata": {
        "id": "QlO5Ab2uUNNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Text"
      ],
      "metadata": {
        "id": "0C2bDC5tUmwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q3a3FYN-2q55"
      },
      "outputs": [],
      "source": [
        "text = \"\"\" \n",
        "ummarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while at the same time preserving key informational elements and the meaning of content. Since manual text summarization is a time expensive and generally laborious task, the automatization of the task is gaining increasing popularity and therefore constitutes a strong motivation for academic research.\n",
        "There are important applications for text summarization in various NLP related tasks such as text classification, question answering, legal texts summarization, news summarization, and headline generation. Moreover, the generation of summaries can be integrated into these systems as an intermediate stage which helps to reduce the length of the document.\n",
        "In the big data era, there has been an explosion in the amount of text data from a variety of sources. This volume of text is an inestimable source of information and knowledge which needs to be effectively summarized to be useful. This increasing availability of documents has demanded exhaustive research in the NLP area for automatic text summarization. Automatic text summarization is the task of producing a concise and fluent summary without any human help while preserving the meaning of the original text document.\n",
        "It is very challenging, because when we as humans summarize a piece of text, we usually read it entirely to develop our understanding, and then write a summary highlighting its main points. Since computers lack human knowledge and language capability, it makes automatic text summarization a very difficult and non-trivial task.\n",
        "Various models based on machine learning have been proposed for this task. Most of these approaches model this problem as a classification problem which outputs whether to include a sentence in the summary or not. Other approaches have used topic information, Latent Semantic Analysis (LSA), Sequence to Sequence models, Reinforcement Learning and Adversarial processes.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WdjMGdH5UK37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Library"
      ],
      "metadata": {
        "id": "EqQzoPusUsns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "922Encqa3ByR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS"
      ],
      "metadata": {
        "id": "kMGVjBJ93B9G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation"
      ],
      "metadata": {
        "id": "Ybz13MFH3CAh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stopword"
      ],
      "metadata": {
        "id": "jOq9j8cFUw37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = list(STOP_WORDS)"
      ],
      "metadata": {
        "id": "mxQA8Q_J3CDX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "ksvjoxam3CGA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "Lx4yTKVZ3CIV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "anKzF6ZbU4zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qZgSglp3CK9",
        "outputId": "53dafed0-fb00-4a4f-8d2f-bca40934ff60"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' \\n', 'ummarization', 'is', 'the', 'task', 'of', 'condensing', 'a', 'piece', 'of', 'text', 'to', 'a', 'shorter', 'version', ',', 'reducing', 'the', 'size', 'of', 'the', 'initial', 'text', 'while', 'at', 'the', 'same', 'time', 'preserving', 'key', 'informational', 'elements', 'and', 'the', 'meaning', 'of', 'content', '.', 'Since', 'manual', 'text', 'summarization', 'is', 'a', 'time', 'expensive', 'and', 'generally', 'laborious', 'task', ',', 'the', 'automatization', 'of', 'the', 'task', 'is', 'gaining', 'increasing', 'popularity', 'and', 'therefore', 'constitutes', 'a', 'strong', 'motivation', 'for', 'academic', 'research', '.', '\\n', 'There', 'are', 'important', 'applications', 'for', 'text', 'summarization', 'in', 'various', 'NLP', 'related', 'tasks', 'such', 'as', 'text', 'classification', ',', 'question', 'answering', ',', 'legal', 'texts', 'summarization', ',', 'news', 'summarization', ',', 'and', 'headline', 'generation', '.', 'Moreover', ',', 'the', 'generation', 'of', 'summaries', 'can', 'be', 'integrated', 'into', 'these', 'systems', 'as', 'an', 'intermediate', 'stage', 'which', 'helps', 'to', 'reduce', 'the', 'length', 'of', 'the', 'document', '.', '\\n', 'In', 'the', 'big', 'data', 'era', ',', 'there', 'has', 'been', 'an', 'explosion', 'in', 'the', 'amount', 'of', 'text', 'data', 'from', 'a', 'variety', 'of', 'sources', '.', 'This', 'volume', 'of', 'text', 'is', 'an', 'inestimable', 'source', 'of', 'information', 'and', 'knowledge', 'which', 'needs', 'to', 'be', 'effectively', 'summarized', 'to', 'be', 'useful', '.', 'This', 'increasing', 'availability', 'of', 'documents', 'has', 'demanded', 'exhaustive', 'research', 'in', 'the', 'NLP', 'area', 'for', 'automatic', 'text', 'summarization', '.', 'Automatic', 'text', 'summarization', 'is', 'the', 'task', 'of', 'producing', 'a', 'concise', 'and', 'fluent', 'summary', 'without', 'any', 'human', 'help', 'while', 'preserving', 'the', 'meaning', 'of', 'the', 'original', 'text', 'document', '.', '\\n', 'It', 'is', 'very', 'challenging', ',', 'because', 'when', 'we', 'as', 'humans', 'summarize', 'a', 'piece', 'of', 'text', ',', 'we', 'usually', 'read', 'it', 'entirely', 'to', 'develop', 'our', 'understanding', ',', 'and', 'then', 'write', 'a', 'summary', 'highlighting', 'its', 'main', 'points', '.', 'Since', 'computers', 'lack', 'human', 'knowledge', 'and', 'language', 'capability', ',', 'it', 'makes', 'automatic', 'text', 'summarization', 'a', 'very', 'difficult', 'and', 'non', '-', 'trivial', 'task', '.', '\\n', 'Various', 'models', 'based', 'on', 'machine', 'learning', 'have', 'been', 'proposed', 'for', 'this', 'task', '.', 'Most', 'of', 'these', 'approaches', 'model', 'this', 'problem', 'as', 'a', 'classification', 'problem', 'which', 'outputs', 'whether', 'to', 'include', 'a', 'sentence', 'in', 'the', 'summary', 'or', 'not', '.', 'Other', 'approaches', 'have', 'used', 'topic', 'information', ',', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', ',', 'Sequence', 'to', 'Sequence', 'models', ',', 'Reinforcement', 'Learning', 'and', 'Adversarial', 'processes', '.', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#punctuation = punctuation+\"\\n\"\n",
        "punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qd8lIvk35ihH",
        "outputId": "0129823e-c672-4c8d-ef8c-48148768c68b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Frequency Dictionary"
      ],
      "metadata": {
        "id": "S-z4RTiOU84b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequency = {}\n",
        "for word in doc:\n",
        "  if word.text.lower() not in stopwords:\n",
        "    if word.text.lower() not in punctuation:\n",
        "      if word.text not in word_frequency.keys():\n",
        "        word_frequency[word.text] = 1\n",
        "      else:\n",
        "        word_frequency[word.text] +=1"
      ],
      "metadata": {
        "id": "RStrstkf5ijv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_frequency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXJkxhzx5imV",
        "outputId": "cf0d4f6f-4b77-4126-8aa3-d78398792831"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' \\n': 1, 'ummarization': 1, 'task': 6, 'condensing': 1, 'piece': 2, 'text': 12, 'shorter': 1, 'version': 1, 'reducing': 1, 'size': 1, 'initial': 1, 'time': 2, 'preserving': 2, 'key': 1, 'informational': 1, 'elements': 1, 'meaning': 2, 'content': 1, 'manual': 1, 'summarization': 7, 'expensive': 1, 'generally': 1, 'laborious': 1, 'automatization': 1, 'gaining': 1, 'increasing': 2, 'popularity': 1, 'constitutes': 1, 'strong': 1, 'motivation': 1, 'academic': 1, 'research': 2, 'important': 1, 'applications': 1, 'NLP': 2, 'related': 1, 'tasks': 1, 'classification': 2, 'question': 1, 'answering': 1, 'legal': 1, 'texts': 1, 'news': 1, 'headline': 1, 'generation': 2, 'summaries': 1, 'integrated': 1, 'systems': 1, 'intermediate': 1, 'stage': 1, 'helps': 1, 'reduce': 1, 'length': 1, 'document': 2, 'big': 1, 'data': 2, 'era': 1, 'explosion': 1, 'variety': 1, 'sources': 1, 'volume': 1, 'inestimable': 1, 'source': 1, 'information': 2, 'knowledge': 2, 'needs': 1, 'effectively': 1, 'summarized': 1, 'useful': 1, 'availability': 1, 'documents': 1, 'demanded': 1, 'exhaustive': 1, 'area': 1, 'automatic': 2, 'Automatic': 1, 'producing': 1, 'concise': 1, 'fluent': 1, 'summary': 3, 'human': 2, 'help': 1, 'original': 1, 'challenging': 1, 'humans': 1, 'summarize': 1, 'usually': 1, 'read': 1, 'entirely': 1, 'develop': 1, 'understanding': 1, 'write': 1, 'highlighting': 1, 'main': 1, 'points': 1, 'computers': 1, 'lack': 1, 'language': 1, 'capability': 1, 'makes': 1, 'difficult': 1, 'non': 1, 'trivial': 1, 'models': 2, 'based': 1, 'machine': 1, 'learning': 1, 'proposed': 1, 'approaches': 2, 'model': 1, 'problem': 2, 'outputs': 1, 'include': 1, 'sentence': 1, 'topic': 1, 'Latent': 1, 'Semantic': 1, 'Analysis': 1, 'LSA': 1, 'Sequence': 2, 'Reinforcement': 1, 'Learning': 1, 'Adversarial': 1, 'processes': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequency = max(word_frequency.values())\n",
        "max_frequency\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4sIPRaL5io1",
        "outputId": "76318518-c5c3-4440-c01a-9f9a9a9bf3d8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_frequency.keys():\n",
        "  word_frequency[word] = word_frequency[word]/max_frequency"
      ],
      "metadata": {
        "id": "LEY_U5EN5irT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tys700u_5iuC",
        "outputId": "c9fd2465-cec9-4752-8b68-7a1cc823c1d5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' \\n': 0.08333333333333333,\n",
              " 'Adversarial': 0.08333333333333333,\n",
              " 'Analysis': 0.08333333333333333,\n",
              " 'Automatic': 0.08333333333333333,\n",
              " 'LSA': 0.08333333333333333,\n",
              " 'Latent': 0.08333333333333333,\n",
              " 'Learning': 0.08333333333333333,\n",
              " 'NLP': 0.16666666666666666,\n",
              " 'Reinforcement': 0.08333333333333333,\n",
              " 'Semantic': 0.08333333333333333,\n",
              " 'Sequence': 0.16666666666666666,\n",
              " 'academic': 0.08333333333333333,\n",
              " 'answering': 0.08333333333333333,\n",
              " 'applications': 0.08333333333333333,\n",
              " 'approaches': 0.16666666666666666,\n",
              " 'area': 0.08333333333333333,\n",
              " 'automatic': 0.16666666666666666,\n",
              " 'automatization': 0.08333333333333333,\n",
              " 'availability': 0.08333333333333333,\n",
              " 'based': 0.08333333333333333,\n",
              " 'big': 0.08333333333333333,\n",
              " 'capability': 0.08333333333333333,\n",
              " 'challenging': 0.08333333333333333,\n",
              " 'classification': 0.16666666666666666,\n",
              " 'computers': 0.08333333333333333,\n",
              " 'concise': 0.08333333333333333,\n",
              " 'condensing': 0.08333333333333333,\n",
              " 'constitutes': 0.08333333333333333,\n",
              " 'content': 0.08333333333333333,\n",
              " 'data': 0.16666666666666666,\n",
              " 'demanded': 0.08333333333333333,\n",
              " 'develop': 0.08333333333333333,\n",
              " 'difficult': 0.08333333333333333,\n",
              " 'document': 0.16666666666666666,\n",
              " 'documents': 0.08333333333333333,\n",
              " 'effectively': 0.08333333333333333,\n",
              " 'elements': 0.08333333333333333,\n",
              " 'entirely': 0.08333333333333333,\n",
              " 'era': 0.08333333333333333,\n",
              " 'exhaustive': 0.08333333333333333,\n",
              " 'expensive': 0.08333333333333333,\n",
              " 'explosion': 0.08333333333333333,\n",
              " 'fluent': 0.08333333333333333,\n",
              " 'gaining': 0.08333333333333333,\n",
              " 'generally': 0.08333333333333333,\n",
              " 'generation': 0.16666666666666666,\n",
              " 'headline': 0.08333333333333333,\n",
              " 'help': 0.08333333333333333,\n",
              " 'helps': 0.08333333333333333,\n",
              " 'highlighting': 0.08333333333333333,\n",
              " 'human': 0.16666666666666666,\n",
              " 'humans': 0.08333333333333333,\n",
              " 'important': 0.08333333333333333,\n",
              " 'include': 0.08333333333333333,\n",
              " 'increasing': 0.16666666666666666,\n",
              " 'inestimable': 0.08333333333333333,\n",
              " 'information': 0.16666666666666666,\n",
              " 'informational': 0.08333333333333333,\n",
              " 'initial': 0.08333333333333333,\n",
              " 'integrated': 0.08333333333333333,\n",
              " 'intermediate': 0.08333333333333333,\n",
              " 'key': 0.08333333333333333,\n",
              " 'knowledge': 0.16666666666666666,\n",
              " 'laborious': 0.08333333333333333,\n",
              " 'lack': 0.08333333333333333,\n",
              " 'language': 0.08333333333333333,\n",
              " 'learning': 0.08333333333333333,\n",
              " 'legal': 0.08333333333333333,\n",
              " 'length': 0.08333333333333333,\n",
              " 'machine': 0.08333333333333333,\n",
              " 'main': 0.08333333333333333,\n",
              " 'makes': 0.08333333333333333,\n",
              " 'manual': 0.08333333333333333,\n",
              " 'meaning': 0.16666666666666666,\n",
              " 'model': 0.08333333333333333,\n",
              " 'models': 0.16666666666666666,\n",
              " 'motivation': 0.08333333333333333,\n",
              " 'needs': 0.08333333333333333,\n",
              " 'news': 0.08333333333333333,\n",
              " 'non': 0.08333333333333333,\n",
              " 'original': 0.08333333333333333,\n",
              " 'outputs': 0.08333333333333333,\n",
              " 'piece': 0.16666666666666666,\n",
              " 'points': 0.08333333333333333,\n",
              " 'popularity': 0.08333333333333333,\n",
              " 'preserving': 0.16666666666666666,\n",
              " 'problem': 0.16666666666666666,\n",
              " 'processes': 0.08333333333333333,\n",
              " 'producing': 0.08333333333333333,\n",
              " 'proposed': 0.08333333333333333,\n",
              " 'question': 0.08333333333333333,\n",
              " 'read': 0.08333333333333333,\n",
              " 'reduce': 0.08333333333333333,\n",
              " 'reducing': 0.08333333333333333,\n",
              " 'related': 0.08333333333333333,\n",
              " 'research': 0.16666666666666666,\n",
              " 'sentence': 0.08333333333333333,\n",
              " 'shorter': 0.08333333333333333,\n",
              " 'size': 0.08333333333333333,\n",
              " 'source': 0.08333333333333333,\n",
              " 'sources': 0.08333333333333333,\n",
              " 'stage': 0.08333333333333333,\n",
              " 'strong': 0.08333333333333333,\n",
              " 'summaries': 0.08333333333333333,\n",
              " 'summarization': 0.5833333333333334,\n",
              " 'summarize': 0.08333333333333333,\n",
              " 'summarized': 0.08333333333333333,\n",
              " 'summary': 0.25,\n",
              " 'systems': 0.08333333333333333,\n",
              " 'task': 0.5,\n",
              " 'tasks': 0.08333333333333333,\n",
              " 'text': 1.0,\n",
              " 'texts': 0.08333333333333333,\n",
              " 'time': 0.16666666666666666,\n",
              " 'topic': 0.08333333333333333,\n",
              " 'trivial': 0.08333333333333333,\n",
              " 'ummarization': 0.08333333333333333,\n",
              " 'understanding': 0.08333333333333333,\n",
              " 'useful': 0.08333333333333333,\n",
              " 'usually': 0.08333333333333333,\n",
              " 'variety': 0.08333333333333333,\n",
              " 'version': 0.08333333333333333,\n",
              " 'volume': 0.08333333333333333,\n",
              " 'write': 0.08333333333333333}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = [sent for sent in doc.sents]\n",
        "sentence_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksCOSKur5iwo",
        "outputId": "96201e7e-dd0e-4fa4-8e6e-b7b4908b8ece"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ \n",
              " ummarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while at the same time preserving key informational elements and the meaning of content.,\n",
              " Since manual text summarization is a time expensive and generally laborious task, the automatization of the task is gaining increasing popularity and therefore constitutes a strong motivation for academic research.,\n",
              " There are important applications for text summarization in various NLP related tasks such as text classification, question answering, legal texts summarization, news summarization, and headline generation.,\n",
              " Moreover, the generation of summaries can be integrated into these systems as an intermediate stage which helps to reduce the length of the document.,\n",
              " In the big data era, there has been an explosion in the amount of text data from a variety of sources.,\n",
              " This volume of text is an inestimable source of information and knowledge which needs to be effectively summarized to be useful.,\n",
              " This increasing availability of documents has demanded exhaustive research in the NLP area for automatic text summarization.,\n",
              " Automatic text summarization is the task of producing a concise and fluent summary without any human help while preserving the meaning of the original text document.,\n",
              " It is very challenging, because when we as humans summarize a piece of text, we usually read it entirely to develop our understanding, and then write a summary highlighting its main points.,\n",
              " Since computers lack human knowledge and language capability, it makes automatic text summarization a very difficult and non-trivial task.,\n",
              " Various models based on machine learning have been proposed for this task.,\n",
              " Most of these approaches model this problem as a classification problem which outputs whether to include a sentence in the summary or not.,\n",
              " Other approaches have used topic information, Latent Semantic Analysis (LSA), Sequence to Sequence models, Reinforcement Learning and Adversarial processes.]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_score = {}\n",
        "for sent in sentence_tokens:\n",
        "  for word in sent:\n",
        "    if word.text.lower() in word_frequency.keys():\n",
        "      if sent not in sentence_score.keys():\n",
        "        sentence_score[sent] = word_frequency[word.text.lower()]\n",
        "      else:\n",
        "        sentence_score[sent] += word_frequency[word.text.lower()]\n"
      ],
      "metadata": {
        "id": "or76jaECGMt6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4cMs16aGMwS",
        "outputId": "80509d9c-d766-4a76-9728-42f62f92f472"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{ \n",
              " ummarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while at the same time preserving key informational elements and the meaning of content.: 4.166666666666667,\n",
              " Since manual text summarization is a time expensive and generally laborious task, the automatization of the task is gaining increasing popularity and therefore constitutes a strong motivation for academic research.: 4.000000000000001,\n",
              " There are important applications for text summarization in various NLP related tasks such as text classification, question answering, legal texts summarization, news summarization, and headline generation.: 4.916666666666666,\n",
              " Moreover, the generation of summaries can be integrated into these systems as an intermediate stage which helps to reduce the length of the document.: 1.0,\n",
              " In the big data era, there has been an explosion in the amount of text data from a variety of sources.: 1.7499999999999998,\n",
              " This volume of text is an inestimable source of information and knowledge which needs to be effectively summarized to be useful.: 1.9166666666666663,\n",
              " This increasing availability of documents has demanded exhaustive research in the NLP area for automatic text summarization.: 2.5,\n",
              " Automatic text summarization is the task of producing a concise and fluent summary without any human help while preserving the meaning of the original text document.: 4.583333333333334,\n",
              " It is very challenging, because when we as humans summarize a piece of text, we usually read it entirely to develop our understanding, and then write a summary highlighting its main points.: 2.4166666666666665,\n",
              " Since computers lack human knowledge and language capability, it makes automatic text summarization a very difficult and non-trivial task.: 3.2500000000000004,\n",
              " Various models based on machine learning have been proposed for this task.: 1.0,\n",
              " Most of these approaches model this problem as a classification problem which outputs whether to include a sentence in the summary or not.: 1.25,\n",
              " Other approaches have used topic information, Latent Semantic Analysis (LSA), Sequence to Sequence models, Reinforcement Learning and Adversarial processes.: 0.75}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from heapq import nlargest"
      ],
      "metadata": {
        "id": "3kV3l53gGMy0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "select_length = int(len(sentence_tokens)*0.3)"
      ],
      "metadata": {
        "id": "atfqxYqmGM1N"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = nlargest(select_length, sentence_score, key = sentence_score.get)"
      ],
      "metadata": {
        "id": "BjlM3ja9GM3u"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# final Summary"
      ],
      "metadata": {
        "id": "SqRjM2VzVH8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOpWU6psGM6W",
        "outputId": "0813ca84-9387-4399-c99c-cdcde186e74e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[There are important applications for text summarization in various NLP related tasks such as text classification, question answering, legal texts summarization, news summarization, and headline generation.,\n",
              " Automatic text summarization is the task of producing a concise and fluent summary without any human help while preserving the meaning of the original text document.,\n",
              "  \n",
              " ummarization is the task of condensing a piece of text to a shorter version, reducing the size of the initial text while at the same time preserving key informational elements and the meaning of content.]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "44BjhyJNGM9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-os8YJtiGM_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wlCNI-ebGNB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3zyuPkuT3COm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}